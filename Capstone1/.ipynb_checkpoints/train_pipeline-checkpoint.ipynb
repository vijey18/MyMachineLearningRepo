{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccccb1-3d24-4e0c-83de-a3210b9ce9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"GRAPE_QUALITY.csv\")\n",
    "new_data = data.drop(columns=['sample_id', 'harvest_date'])\n",
    "\n",
    "# Split features and target variables\n",
    "X = new_data.drop(columns=['quality_category', 'quality_score'])\n",
    "y_category = new_data['quality_category']\n",
    "y_score = new_data['quality_score']\n",
    "\n",
    "# Split data into train/validation/test sets (60/20/20)\n",
    "X_train, X_temp, y_category_train, y_category_temp, y_score_train, y_score_temp = train_test_split(\n",
    "    X, y_category, y_score, test_size=0.4, random_state=25\n",
    ")\n",
    "X_val, X_test, y_category_val, y_category_test, y_score_val, y_score_test = train_test_split(\n",
    "    X_temp, y_category_temp, y_score_temp, test_size=0.5, random_state=25\n",
    ")\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_columns = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "num_columns = [col for col in X_train.columns if X_train[col].dtype in ['int', 'float']]\n",
    "\n",
    "# Preprocessing pipelines\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', categorical_transformer, cat_columns),\n",
    "    ('num', numerical_transformer, num_columns)\n",
    "])\n",
    "\n",
    "# Define parameter grids\n",
    "classification_params = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "regression_params = {\n",
    "    'model__n_estimators': [50, 100, 150],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Classifier pipeline and hyperparameter tuning\n",
    "classifier_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=25))\n",
    "])\n",
    "\n",
    "grid_search_classifier = GridSearchCV(\n",
    "    estimator=classifier_pipeline,\n",
    "    param_grid=classification_params,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_classifier.fit(X_train, y_category_train)\n",
    "best_classifier = grid_search_classifier.best_estimator_\n",
    "print(\"Best Classifier Parameters:\", grid_search_classifier.best_params_)\n",
    "\n",
    "# Regressor pipeline and hyperparameter tuning\n",
    "regression_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', GradientBoostingRegressor(random_state=25))\n",
    "])\n",
    "\n",
    "grid_search_regressor = GridSearchCV(\n",
    "    estimator=regression_pipeline,\n",
    "    param_grid=regression_params,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_regressor.fit(X_train, y_score_train)\n",
    "best_regressor = grid_search_regressor.best_estimator_\n",
    "print(\"Best Regressor Parameters:\", grid_search_regressor.best_params_)\n",
    "\n",
    "# Combined model\n",
    "class CombinedGradientBoosting:\n",
    "    def __init__(self, classification_model, regression_model):\n",
    "        self.classification = classification_model\n",
    "        self.regression = regression_model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classification.fit(X, y['quality_category'])\n",
    "        self.regression.fit(X, y['quality_score'])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        classification_preds = self.classification.predict(X)\n",
    "        regression_preds = self.regression.predict(X)\n",
    "        return pd.DataFrame({\n",
    "            'quality_category': classification_preds,\n",
    "            'quality_score': regression_preds\n",
    "        }, index=X.index)\n",
    "\n",
    "# Multi-output model combining both\n",
    "optimized_model = CombinedGradientBoosting(\n",
    "    classification_model=best_classifier,\n",
    "    regression_model=best_regressor\n",
    ")\n",
    "\n",
    "# Fit the combined model\n",
    "optimized_model.fit(X_train, pd.concat([y_category_train, y_score_train], axis=1))\n",
    "\n",
    "# Save the pipeline\n",
    "joblib.dump(optimized_model, 'optimized_combined_model.pkl')\n",
    "print(\"Optimized model saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
