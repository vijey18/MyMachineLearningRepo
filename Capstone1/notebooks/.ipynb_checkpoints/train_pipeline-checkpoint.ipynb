{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfccccb1-3d24-4e0c-83de-a3210b9ce9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from kaggle) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: python-slugify in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: webencodings in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/envs/grape-prediction-env/lib/python3.9/site-packages (from requests->kaggle) (3.7)\n",
      "Dataset URL: https://www.kaggle.com/datasets/mrmars1010/grape-quality\n",
      "License(s): apache-2.0\n",
      "Downloading grape-quality.zip to /home/ubuntu/machine-learning-zoomcamp/MyMachineLearningRepo/Capstone1/data\n",
      "  0%|                                               | 0.00/26.8k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 26.8k/26.8k [00:00<00:00, 19.0MB/s]\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best Classifier Parameters: {'classifier__learning_rate': 0.05, 'classifier__max_depth': 3, 'classifier__n_estimators': 200}\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best Regressor Parameters: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_samples_split': 10, 'model__n_estimators': 150}\n",
      "Optimized model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!kaggle datasets download mrmars1010/grape-quality -p /home/ubuntu/machine-learning-zoomcamp/MyMachineLearningRepo/Capstone1/data --unzip\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"../data/GRAPE_QUALITY.csv\")\n",
    "new_data = data.drop(columns=['sample_id', 'harvest_date'])\n",
    "\n",
    "# Split features and target variables\n",
    "X = new_data.drop(columns=['quality_category', 'quality_score'])\n",
    "y_category = new_data['quality_category']\n",
    "y_score = new_data['quality_score']\n",
    "\n",
    "# Split data into train/validation/test sets (60/20/20)\n",
    "X_train, X_temp, y_category_train, y_category_temp, y_score_train, y_score_temp = train_test_split(\n",
    "    X, y_category, y_score, test_size=0.4, random_state=25\n",
    ")\n",
    "X_val, X_test, y_category_val, y_category_test, y_score_val, y_score_test = train_test_split(\n",
    "    X_temp, y_category_temp, y_score_temp, test_size=0.5, random_state=25\n",
    ")\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_columns = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "num_columns = [col for col in X_train.columns if X_train[col].dtype in ['int', 'float']]\n",
    "\n",
    "# Preprocessing pipelines\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', categorical_transformer, cat_columns),\n",
    "    ('num', numerical_transformer, num_columns)\n",
    "])\n",
    "\n",
    "# Define parameter grids\n",
    "classification_params = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "regression_params = {\n",
    "    'model__n_estimators': [50, 100, 150],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Classifier pipeline and hyperparameter tuning\n",
    "classifier_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=25))\n",
    "])\n",
    "\n",
    "grid_search_classifier = GridSearchCV(\n",
    "    estimator=classifier_pipeline,\n",
    "    param_grid=classification_params,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_classifier.fit(X_train, y_category_train)\n",
    "best_classifier = grid_search_classifier.best_estimator_\n",
    "print(\"Best Classifier Parameters:\", grid_search_classifier.best_params_)\n",
    "\n",
    "# Regressor pipeline and hyperparameter tuning\n",
    "regression_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', GradientBoostingRegressor(random_state=25))\n",
    "])\n",
    "\n",
    "grid_search_regressor = GridSearchCV(\n",
    "    estimator=regression_pipeline,\n",
    "    param_grid=regression_params,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_regressor.fit(X_train, y_score_train)\n",
    "best_regressor = grid_search_regressor.best_estimator_\n",
    "print(\"Best Regressor Parameters:\", grid_search_regressor.best_params_)\n",
    "\n",
    "# Combined model\n",
    "class CombinedGradientBoosting:\n",
    "    def __init__(self, classification_model, regression_model):\n",
    "        self.classification = classification_model\n",
    "        self.regression = regression_model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classification.fit(X, y['quality_category'])\n",
    "        self.regression.fit(X, y['quality_score'])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        classification_preds = self.classification.predict(X)\n",
    "        regression_preds = self.regression.predict(X)\n",
    "        return pd.DataFrame({\n",
    "            'quality_category': classification_preds,\n",
    "            'quality_score': regression_preds\n",
    "        }, index=X.index)\n",
    "\n",
    "# Multi-output model combining both\n",
    "optimized_model = CombinedGradientBoosting(\n",
    "    classification_model=best_classifier,\n",
    "    regression_model=best_regressor\n",
    ")\n",
    "\n",
    "# Fit the combined model\n",
    "optimized_model.fit(X_train, pd.concat([y_category_train, y_score_train], axis=1))\n",
    "\n",
    "# Save the pipeline\n",
    "joblib.dump(optimized_model, 'optimized_combined_model.pkl')\n",
    "print(\"Optimized model saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
